# Detailed Implementation of Multi-Layer Perceptron
This repo contains the detailed implementation of Multi-Layer Perceptron from scratch and comparing the performance of MLP network on multiple datasets. 

* Understanding the MLP architecture from scratch
* Understanding Forward Propagation, Backpropagation, Activation Functions, Softmax and Loss function (Cross Entropy)
* Making predictions and evaluating performance on various linear and non-linear datasets
* Visualising the decision boundary using Matplotlib
* Model parameters including the input size, output size and the hidden layers caan be customized.

The default parameters for the model construct a network with 2 hidden layers but these parameters can be customised.
